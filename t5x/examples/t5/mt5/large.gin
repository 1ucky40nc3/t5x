# mT5 Large model.

include 't5x/examples/t5/mt5/base.gin'  # imports vocab, optimizer and model.

# ------------------- Network specification overrides --------------------------
network.Transformer.config = @network.T5Config()
network.T5Config:
  vocab_size = 250112  # vocab size rounded to a multiple of 128 for TPU efficiency
  dtype = 'bfloat16'
  emb_dim = 1024
  num_heads = 16
  num_encoder_layers = 24
  num_decoder_layers = 24
  head_dim = 64
  mlp_dim = 2816
  mlp_activations = ('gelu', 'linear')
  dropout_rate = 0.0
  logits_via_embedding = False
