# ByT5 XL model.

include 't5x/examples/t5/byt5/base.gin'  # imports vocab, optimizer and model.

# ------------------- Network specification overrides --------------------------
network.Transformer.config = @network.T5Config()
network.T5Config:
  vocab_size = 384  # vocab size rounded to a multiple of 128 for TPU efficiency
  dtype = 'bfloat16'
  emb_dim = 2560
  num_heads = 32
  num_encoder_layers = 36
  num_decoder_layers = 12
  head_dim = 64
  mlp_dim = 6720
  mlp_activations = ('gelu', 'linear')
  dropout_rate = 0.0
  logits_via_embedding = False
